{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPartitioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "f_Uv3CGA4Uxt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02JZIKHf3-ss",
        "colab_type": "text"
      },
      "source": [
        "## ESoWC 2019: Data-driven feature selection towards improving forecast-based prediction of wildfire hazard\n",
        "\n",
        "Team: [@mariajoaosousa](https://github.com/mariajoaosousa), [@eduardogfma](https://github.com/eduardogfma)\n",
        "\n",
        "Project github page: [https://github.com/esowc/ml_fire](https://github.com/esowc/ml_fire)\n",
        "\n",
        "# Data partitioning\n",
        "\n",
        "This notebook focuses on partitioning the datasets into train and test sets. The work was developed using [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb), a free Jupyter notebook environment that runs entirely in the cloud and enables complete integration with Google Drive.\n",
        "\n",
        "The note book is structured as follows. Section 1 focuses on a very brief introduction to Colaboratory. In Section 2, data partitionig and cross-validation are discussed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxlJiYFA6xI1",
        "colab_type": "text"
      },
      "source": [
        "# 1. Colaboratory\n",
        "\n",
        "*The present section focuses on a very brief introduction to [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) and it is not intended to be taken as an alternative to the official tutorials and documentation.*\n",
        "\n",
        "Navigationwise, Colaboratory offers an easy way to access specific sections and files available on a virtual disk. On the left the user can find the **Table of contents** and the **Files** tabs. The **Code snnipets** tab is a convinient way of *copying and pasting* already developed code for standard operations.\n",
        "\n",
        "For this particular project, however, there are two particular features of the Colaboratory environment that should be stressed. Namely, the possibility of:\n",
        "\n",
        "* making use of GPU/TPU for parallell copmuting,\n",
        "* installing additional python dependencies,\n",
        "* mouting the Google Drive on the virtual disk, enabling the user to easily import/export data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCBZP3dtAIp1",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Runtime type\n",
        "\n",
        "To define or redefine the Runtime type in Colaboratory, the user must simply go to *Runtime -> Change runtime type* and select the desired properties.\n",
        "\n",
        "Regarding the hardware accelarator options, it should be noted they influence the available session's memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d625DFo8par",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Installing additional dependencies\n",
        "\n",
        "The Colaboratory environment is built on Linux. Thus it is possible to access the console by using the `!` prefix. The next code cell intstalls the `netcdf4` library in the current python environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C5QgQH7fGje",
        "colab_type": "code",
        "outputId": "17f46bc0-800b-4f6f-9477-b9faac2e3909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install netcdf4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (1.5.1.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.0.3.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD5HhKlBDbUM",
        "colab_type": "text"
      },
      "source": [
        "The most used libraries are already installed by default. However, in some non-standard situations it may be necessary to install several dependencies. In that case, there exists also the possibility of installing anaconda. Since this notebook does not require such preparations, we skip that topic for now with the promisse to revisit it in the future, if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv49n6DD8dM9",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Mounting Google Drive\n",
        "\n",
        "To be able to access files from Google Drive, it must be first mounted. For security reasons this operation requires the user to introduce an authorization code. The process is quick and easy: follow the presented link, copy the code and pasted into the input space (the rectangle presented on the code cell output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQqzMqVDfWLc",
        "colab_type": "code",
        "outputId": "4da645f6-7069-4f39-c34e-bb232edcb5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpPAKNUtktGR",
        "colab_type": "text"
      },
      "source": [
        "# 2. Processing data\n",
        "\n",
        "Supervised learning is characterized by providing the *features*, $X$, and *labels*, $y$ (i.e. the target values) to the model. In this framework, the modelling process is formulated as an optimization problem where the error between the predicted output, $\\hat{y}$, and the true output, $y$, must be minimised.\n",
        "\n",
        "The modelling process is usually called *training*. In turn, to evaluate the model's performance, a set of tests must be performed. This process is called *testing*. In this phase, two things must be assessed:\n",
        "\n",
        "1. how good is the model's prediction, i.e. how close are $\\hat{y}$ and $y$?\n",
        "2. how generic is the model, i.e. provided new data is the model able to deliever good predictions?\n",
        "\n",
        "Learning a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called **overfitting**. To avoid it, in supervised learning one needs a *training set* and a *test set* [[1](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)]. Where each set contains both features and labels. A third set may also be provided, the *validation set* -- to be used during training and provide information about the model's learning.\n",
        "\n",
        "This section focuses on data partitioning, i.e. creating the train and test datasets from the available raw data. The data used comprises 3 datasets -- FWI, BUI, ISI. (For more information about the used data, refer to the [Getting Started With Data tutorials](https://github.com/esowc/ml_fire/tree/master/GettingStartedWithData).) Each one of these datasets are loaded as `xarray.Dataset` and then stored in a dictionary (`rawData`) for easy access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B8Mn47efWvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import KFold\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL1Yul14abgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawData ={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUolV5IilUJ",
        "colab_type": "code",
        "outputId": "4c6f26f6-5921-4f08-d78f-4837fe4cedc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "rawData[\"fwi\"] = xr.open_dataset(\"../content/gdrive/My Drive/ESoWC/datasets/segmented_data/GADM/fwiCAN_GADM00.nc\")\n",
        "rawData[\"fwi\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:  (lat: 45, lon: 162, time: 14061)\n",
              "Coordinates:\n",
              "  * lat      (lat) float32 73.33297 72.63123 71.92949 ... 43.15779 42.45604\n",
              "  * lon      (lon) float32 -149.76562 -149.0625 ... -37.265625 -36.5625\n",
              "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2018-06-30\n",
              "Data variables:\n",
              "    fwi      (time, lat, lon) float32 ...\n",
              "Attributes:\n",
              "    CDI:               Climate Data Interface version 1.8.2 (http://mpimet.mp...\n",
              "    history:           Fri Aug 31 16:18:06 2018: cdo cat /hugetmp/fire/geff/r...\n",
              "    Conventions:       CF-1.6\n",
              "    Reference date:    19800101\n",
              "    ECMWF fire model:  2.2\n",
              "    Lincense:          Copernicus\n",
              "    version:           2.2\n",
              "    NCO:               4.6.7\n",
              "    CDO:               Climate Data Operators version 1.8.2 (http://mpimet.mp..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBnwvlm1kLCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawData[\"isi\"] = xr.open_dataset(\"../content/gdrive/My Drive/ESoWC/datasets/segmented_data/GADM/isiCAN_GADM00.nc\")\n",
        "rawData[\"bui\"] = xr.open_dataset(\"../content/gdrive/My Drive/ESoWC/datasets/segmented_data/GADM/buiCAN_GADM00.nc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29jMrerQa3Wb",
        "colab_type": "code",
        "outputId": "4cc4fcc8-c7b0-48fe-cf50-53e5685c15df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "rawData.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['fwi', 'isi', 'bui'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOwW28k-vCWa",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Cross validation\n",
        "\n",
        "*The contents of this section is based on the scikit-learn official [documentation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).*\n",
        "\n",
        "By partitioning the available (raw) data into 3 sets -- train, test, validation -- the number of sample which can be used for learning are drastically reduced, and the results can depend on  a particular random choice for the pair of (train, validation) sets.\n",
        "\n",
        "To mittigate this, one can use [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) (CV). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called **k-fold cross-validation**, the training set is split into $k$ smaller sets. The following procedure is followed for each of the $k$ “folds”:\n",
        "\n",
        "* a model is trained using $k-1$ of the folds as training data,\n",
        "* the resulting model is validated on the remaining part of the data (i.e. it is used as a test set to compute a performance measure such as accuracy).\n",
        "\n",
        "One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set) [[2](https://en.wikipedia.org/wiki/Cross-validation_(statistics))]. The process can be graphically represented as follows.\n",
        "\n",
        "![cross-validation_fig1](https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg)\n",
        "\n",
        "Figure 1 -- Cross-validation process.\n",
        "\n",
        "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop, as shown in Figure 2. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set).\n",
        "\n",
        "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
        "\n",
        "Figure 2 -- k-fold cross-validation performance measure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aGDAaus4_FR",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.2. Data partitioning\n",
        "\n",
        "In this section, the functions to partition data in accordance to the cross-validation method are defined. The pseudocode is the following:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "for each dataset in rawData:\n",
        "  partitionedData = {}  # define dictionary\n",
        "  i = 1\n",
        "  for each fold:\n",
        "    data = {}\n",
        "    for each feature\n",
        "      partition dataset into train_data and test_data\n",
        "      data[feature] = {\"train\": train_data, \"test\":test_data}\n",
        "    partitionedData[\"fold_{}\".format(i)] = data\n",
        "    i++\n",
        "  return  partitionedData\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Uv3CGA4Uxt",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "###  *Handle functions*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po62mB7Jc2y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def part(name, train_ind, test_ind):\n",
        "  '''\n",
        "    Cross-validation data partitioning\n",
        "    \n",
        "      name: ..................... [string] feature name\n",
        "      train_ind: ................ [list] indeces to partition data\n",
        "      test_ind: ................. [list] indeces to partition data\n",
        "      \n",
        "      > output: [xr.DataSet] train and test datasets\n",
        "      \n",
        "      Given the indeces, this function partitions data into train and test\n",
        "      datasets. The outputs are xr.DataSet segmented obejcts.\n",
        "  '''\n",
        "  \n",
        "  train, test = rawData[name].isel({'time':train_ind}), rawData[name].isel({'time':test_ind})\n",
        "  \n",
        "  return train, test\n",
        "  \n",
        "  \n",
        "def printInfo(name, train, test):\n",
        "  '''\n",
        "    Prints information abou the partitioned data\n",
        "    \n",
        "      name: ..................... [string] feature name\n",
        "      train: .................... [xr.DataArray] train data\n",
        "      test: ..................... [xr.DataArray] test data\n",
        "      \n",
        "      > output: void\n",
        "      \n",
        "      Prints how many xr.DataArray are comprised in each partitioned dataset\n",
        "  '''\n",
        "  \n",
        "  print(\"\\n  {}_train -- Number of xarrays: \".format(name), len(train.time))\n",
        "  print(\"  {}_test -- Number of xarrays: \".format(name), len(test.time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3T5-yqftUpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cvPartition(n_folds, inputs, output):\n",
        "  '''\n",
        "    Partitions data for cross-validation\n",
        "    \n",
        "    inputs: ..................... [string] list of features\n",
        "    output: ..................... [strings] list of labels\n",
        "    \n",
        "    > output: [dict] partitionedData\n",
        "    \n",
        "    Provided the features and labels, the function outputs a dictionary\n",
        "    containing the partitioned data by fold. The structure of the dictionary \n",
        "    is the  following.\n",
        "    \n",
        "    Fold 1\n",
        "      |\n",
        "      -- bui    ----> input\n",
        "      .  |\n",
        "      .  -- train\n",
        "      .  |\n",
        "      .  -- test\n",
        "      |\n",
        "      -- isi    ----> input\n",
        "      .  |\n",
        "      .  -- train\n",
        "      .  |\n",
        "      .  -- test\n",
        "      .\n",
        "      .\n",
        "      \n",
        "    (...)\n",
        "      \n",
        "      .\n",
        "      .\n",
        "      |\n",
        "      -- fwi    ----> output\n",
        "      .  |\n",
        "      .  -- train\n",
        "      .  |\n",
        "      .  -- test\n",
        "      \n",
        "    (...)\n",
        "      \n",
        "      Fold 2\n",
        "      |\n",
        "      -- bui\n",
        "      .  |\n",
        "      .  -- train\n",
        "      .  |\n",
        "      .  -- test\n",
        "      |\n",
        "      -- isi\n",
        "      .  |\n",
        "      .  -- train\n",
        "      .  |\n",
        "      .  -- test\n",
        "      \n",
        "    (...)\n",
        "    \n",
        "  '''\n",
        "  \n",
        "  # initialisation\n",
        "  partitionedData = {}            \n",
        "  i = 1\n",
        "  x = rawData[inputs[0]][inputs[0]]\n",
        "  inputs.append(output)\n",
        "  \n",
        "  # start partition process\n",
        "  for train_index, test_index in KFold(n_splits=n_folds).split(X=x):\n",
        "\n",
        "    print(\" ---------------- Fold \", i,\"---------------- \")\n",
        "    print(\"TRAIN:\", train_index, \"\\nTEST: \", test_index)\n",
        "\n",
        "\n",
        "    # store data  \n",
        "    data = {}\n",
        "\n",
        "    for feat in inputs:\n",
        "      train, test = part(feat, train_index, test_index)  # partion data\n",
        "      data[feat] = {\"train\": train, \"test\": test}\n",
        "      \n",
        "      # show info\n",
        "      printInfo(feat, train, test)  \n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    partitionedData[\"fold_{}\".format(i)] = data\n",
        "\n",
        "    i +=1\n",
        "    \n",
        "  return partitionedData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvfIEgLK4sZ-",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "### *Partitioning data*\n",
        "\n",
        "With the data already partitioned, two examples are shown below. The first one partitions data into 5 folds, while the second one defines 10 folds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgjAFhFn9Nld",
        "colab_type": "text"
      },
      "source": [
        "#### Example 1: using 5 folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ3OeMs4pySB",
        "colab_type": "code",
        "outputId": "2cd9bc4f-ddf1-4484-9a56-1a210625bdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_folds = 5\n",
        "inputs = [\"bui\",\"isi\"]\n",
        "output = \"fwi\"\n",
        "\n",
        "partitionedData_5Fold = cvPartition(n_folds, inputs, output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ---------------- Fold  1 ---------------- \n",
            "TRAIN: [ 2813  2814  2815 ... 14058 14059 14060] \n",
            "TEST:  [   0    1    2 ... 2810 2811 2812]\n",
            "\n",
            "  bui_train -- Number of xarrays:  11248\n",
            "  bui_test -- Number of xarrays:  2813\n",
            "\n",
            "  isi_train -- Number of xarrays:  11248\n",
            "  isi_test -- Number of xarrays:  2813\n",
            "\n",
            "  fwi_train -- Number of xarrays:  11248\n",
            "  fwi_test -- Number of xarrays:  2813\n",
            "\n",
            "\n",
            " ---------------- Fold  2 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [2813 2814 2815 ... 5622 5623 5624]\n",
            "\n",
            "  bui_train -- Number of xarrays:  11249\n",
            "  bui_test -- Number of xarrays:  2812\n",
            "\n",
            "  isi_train -- Number of xarrays:  11249\n",
            "  isi_test -- Number of xarrays:  2812\n",
            "\n",
            "  fwi_train -- Number of xarrays:  11249\n",
            "  fwi_test -- Number of xarrays:  2812\n",
            "\n",
            "\n",
            " ---------------- Fold  3 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [5625 5626 5627 ... 8434 8435 8436]\n",
            "\n",
            "  bui_train -- Number of xarrays:  11249\n",
            "  bui_test -- Number of xarrays:  2812\n",
            "\n",
            "  isi_train -- Number of xarrays:  11249\n",
            "  isi_test -- Number of xarrays:  2812\n",
            "\n",
            "  fwi_train -- Number of xarrays:  11249\n",
            "  fwi_test -- Number of xarrays:  2812\n",
            "\n",
            "\n",
            " ---------------- Fold  4 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [ 8437  8438  8439 ... 11246 11247 11248]\n",
            "\n",
            "  bui_train -- Number of xarrays:  11249\n",
            "  bui_test -- Number of xarrays:  2812\n",
            "\n",
            "  isi_train -- Number of xarrays:  11249\n",
            "  isi_test -- Number of xarrays:  2812\n",
            "\n",
            "  fwi_train -- Number of xarrays:  11249\n",
            "  fwi_test -- Number of xarrays:  2812\n",
            "\n",
            "\n",
            " ---------------- Fold  5 ---------------- \n",
            "TRAIN: [    0     1     2 ... 11246 11247 11248] \n",
            "TEST:  [11249 11250 11251 ... 14058 14059 14060]\n",
            "\n",
            "  bui_train -- Number of xarrays:  11249\n",
            "  bui_test -- Number of xarrays:  2812\n",
            "\n",
            "  isi_train -- Number of xarrays:  11249\n",
            "  isi_test -- Number of xarrays:  2812\n",
            "\n",
            "  fwi_train -- Number of xarrays:  11249\n",
            "  fwi_test -- Number of xarrays:  2812\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0zwFxGUWR2G",
        "colab_type": "text"
      },
      "source": [
        "#### Example 2: using 10 folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNDbmfej9Xbn",
        "colab_type": "code",
        "outputId": "c5c0e82f-08a7-40b2-b8ac-854830f236a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_folds = 10\n",
        "inputs = [\"bui\",\"isi\"]\n",
        "output = \"fwi\"\n",
        "\n",
        "partitionedData_10Fold = cvPartition(n_folds, inputs, output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ---------------- Fold  1 ---------------- \n",
            "TRAIN: [ 1407  1408  1409 ... 14058 14059 14060] \n",
            "TEST:  [   0    1    2 ... 1404 1405 1406]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12654\n",
            "  bui_test -- Number of xarrays:  1407\n",
            "\n",
            "  isi_train -- Number of xarrays:  12654\n",
            "  isi_test -- Number of xarrays:  1407\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12654\n",
            "  fwi_test -- Number of xarrays:  1407\n",
            "\n",
            "\n",
            " ---------------- Fold  2 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [1407 1408 1409 ... 2810 2811 2812]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  3 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [2813 2814 2815 ... 4216 4217 4218]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  4 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [4219 4220 4221 ... 5622 5623 5624]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  5 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [5625 5626 5627 ... 7028 7029 7030]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  6 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [7031 7032 7033 ... 8434 8435 8436]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  7 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [8437 8438 8439 ... 9840 9841 9842]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  8 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [ 9843  9844  9845 ... 11246 11247 11248]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  9 ---------------- \n",
            "TRAIN: [    0     1     2 ... 14058 14059 14060] \n",
            "TEST:  [11249 11250 11251 ... 12652 12653 12654]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n",
            " ---------------- Fold  10 ---------------- \n",
            "TRAIN: [    0     1     2 ... 12652 12653 12654] \n",
            "TEST:  [12655 12656 12657 ... 14058 14059 14060]\n",
            "\n",
            "  bui_train -- Number of xarrays:  12655\n",
            "  bui_test -- Number of xarrays:  1406\n",
            "\n",
            "  isi_train -- Number of xarrays:  12655\n",
            "  isi_test -- Number of xarrays:  1406\n",
            "\n",
            "  fwi_train -- Number of xarrays:  12655\n",
            "  fwi_test -- Number of xarrays:  1406\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuc2f6fRFnOo",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, data was correctly partitioned. \n",
        "\n",
        "In summary, the data partioning consisted ont the following:\n",
        "\n",
        "* a dictionary to store raw data was instanciated:\n",
        ">`rawData = {\"bui\": bui_data, \"isi\": isi_data, \"fwi\": fwi_data}`,\n",
        "\n",
        " \n",
        "* from `rawData`, data was then partitioned and stored in a new dictionary:\n",
        ">`partitionedData = {\"bui\": bui_Test&Train_data, \"isi\": isi_Test&Train_data, \"fwi\": fwi_Test&Train_data}`."
      ]
    }
  ]
}